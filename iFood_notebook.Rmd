---
title: 'R Notebook: iFood CRM Data Analyst Case'
author: "Eduar Felipe Ria√±o Torres^[felipehuman@gmail.com]"
date: "`r Sys.Date()`"
output:
  pdf_document:
    highlight: pygments
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_document:
    theme: cerulean
    highlight: pygments
  word_document:
    toc: yes
    toc_depth: '4'
subtitle: Business Analysis on Customer Relationship Management
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    #echo    = FALSE,
    message = FALSE,
    warning = FALSE)
```

# Executive Summary

-   A pilot campaign involving **2.240 customers** was carried out, customers who bought the offer were properly labeled. The total cost of the sample campaign was **6.720MU** and the revenue generated by the customers who accepted the offer was **3.674MU**.
-   Globally the campaign had a profit of **-3.046MU** and the success rate of the campaign was **15%**.
-   Through an **Exploratory Data Analysis (EDA)**, it was studied the characteristic features of customers.
-   Based on customers behaviors, it is necessary to create and describe a **customer segmentation**.
-   To maximize the profit of the next marketing campaign profit, it was built a **predictive model** (classification).

# Loading R libraries

I load a range of R libraries for general data wrangling, transformation, analyzing and visualization together with more specialized tools.

```{r}
# summarization
library(skimr)
library(Hmisc)
library(knitr) # some tables and R Markdown
library(correlationfunnel) # correlation Analysis

# articulation with Python
library(reticulate)

# general visualization
library(ggplot2) # visualization
library(scales) # visualization
library(grid) # visualization
library(gridExtra) # visualization
library(RColorBrewer) # visualization
library(corrplot) # visualization
library(reshape2) # visualization
library(hrbrthemes) # visualization

# general data manipulation
library(dplyr) # data manipulation
library(readr) # input/output
library(data.table) # data manipulation
library(tibble) # data wrangling
library(tidyr) # data wrangling
library(stringr) # string manipulation
library(forcats) # factor manipulation
library(tidyverse) # plotting, cleaning, etc
library(gdata)
library(plyr)

# specific visualization
library(alluvial) # visualization
library(ggrepel) # visualization
library(ggforce) # visualization
library(ggridges) # visualization
library(gganimate) # animations
library(gridExtra) # visualization
library(GGally) # visualization
library(ggExtra) # visualization
library(highcharter) # visualization
library(countrycode) # visualization
library(geofacet) # visualization
library(wesanderson) # color palettes
library(treemapify) # visualization
library(cluster) # visualization
library(gridExtra) # visualization
library(grid) # visualization

# specific data manipulation
library(lazyeval) # data wrangling
library(broom) # data wrangling
library(purrr) # string manipulation
library(reshape2) # data wrangling
library(rlang) # encoding

# analysis
library(lubridate)
library(tidyverse)
library(caret)
library(xgboost)
library(modeest)
library(NbClust)
library(factoextra)
library(tidymodels) # framework for ML
library(ranger)
library(randomForest)
library(vip)
library(DataExplorer)
library(tidyquant)
```

# Loading Python libraries

As I did before with R libraries, I import some of the most important libraries in Python.

```{python, warning=FALSE, message=FALSE}
import numpy as np
import pandas as pd
import statistics as stat
import matplotlib.pyplot as plt

import seaborn as sns
sns.set() 
```

```{python, warning=FALSE, message=FALSE}
# Load the main dataset in Python environment
raw_ifood = pd.read_csv('ml_project1_data.csv')
```

# Setting working directory

```{r}
setwd("C:/Users/eduar/Downloads/My Things/Data sets R/iFood")
```

# Loading the main dataset

The dataset contains socio-demographic and firmographic features about 2.240 customers who were contacted. Additionally, it contains a flag for those customers who responded the campaign, by buying the product.

```{r}
# Load the main data set in R environment
raw_ifood <- read.csv("ml_project1_data.csv")
```

# Section 01: Exploratory Data Analysis

This is the first approach to the data set. I am going to analyze the map (dataset) and get a big picture perspective of it. In similar way, to ensure a holistic approach. Once data is imported, it is a good idea to to tidy it. Tidying data, means storing it in a consistent form that matches the semantics of the dataset with the way it stored.

```{python}
raw_ifood.head()
```

```{python}
raw_ifood.shape
```

```{python}
raw_ifood.describe()
```

```{r, fig.height=5.5}
raw_ifood %>% plot_missing(missing_only = FALSE, title = "Missing Values")
```

-   Note: All NAs come from Income column. This means that there is missing Income data for 24 customers, data, and none of the other columns contain any missing data.

```{python}
# Removing data points where Income = NA
print("Number of Datapoints removed Income=NA: ", raw_ifood.isnull().sum().sum())
```

```{r}
raw_ifood <- raw_ifood %>% filter(.,!is.na(Income))
summary(raw_ifood$Income)
```

```{r}
summary(raw_ifood)
```

Throughout the data it is possible to see:

-   2240 customers (observations)
-   29 variables/columns
-   3 character variables (i.e. strings)
-   26 numeric variables (i.e. numbers / floats)

Additionally, I categorize the variables in terms of the 4 P's of marketing:People (customers), Products, Places (channels), and Promotions (discounts and campaigns). The purpose of this classification is to increase the analyst's perspective. It might also provide a great way to segment analytic steps in the Exploratory Data Analysis.

+----------------+------------------+---------------------+-------------------+
| People         | Products         | Place               | Promotion         |
+================+==================+=====================+===================+
| ID             | MntWines         | NumWebPurchases     | NumDealsPurchases |
+----------------+------------------+---------------------+-------------------+
| Year_Birth     | MntFruits        | NumCatalogPurchases | AcceptedCmp1      |
+----------------+------------------+---------------------+-------------------+
| Education      | MntMeatProducts  | NumStorePurchases   | AcceptedCmp2      |
+----------------+------------------+---------------------+-------------------+
| Marital_Status | MntFishProducts  | NumWebVisitsMonth   | AcceptedCmp3      |
+----------------+------------------+---------------------+-------------------+
| Income         | MntSweetProducts |                     | AcceptedCmp4      |
+----------------+------------------+---------------------+-------------------+
| Kidhome        | MntGoldProds     |                     | AcceptedCmp5      |
+----------------+------------------+---------------------+-------------------+
| Teenhome       |                  |                     | Response          |
+----------------+------------------+---------------------+-------------------+
| Dt_Customer    |                  |                     |                   |
+----------------+------------------+---------------------+-------------------+
| Recency        |                  |                     |                   |
+----------------+------------------+---------------------+-------------------+
| Complain       |                  |                     |                   |
+----------------+------------------+---------------------+-------------------+

: 4 P's

```{r}
glimpse(raw_ifood)
```

## Data cleaning before any further process

I have performed some transformations on the variables "Year_Birth", "Income" and "Dt_customer". The main reason is that the syntax of the data contained is not suitable for statistical analysis, such as currency formatting or date formatting.

-   Based on Year_Birth column, bring out Age of Customers.
-   Make Income column numeric and also reformat the data values to remove dollar sign and commas.
-   Make Dt_customer a date column.

```{r}
# Making income numeric
raw_ifood$Income <- as.numeric(raw_ifood$Income %>% gsub("[$,]","",.))
summary(raw_ifood$Income)
```

```{r}
# Extracting Age of Customers. Note: current year = 2021
current_year = 2021 
raw_ifood <-mutate(raw_ifood, Age = current_year - raw_ifood$Year_Birth)
summary(raw_ifood$Age)
```

```{r}
raw_ifood %>%
              ggplot(aes(x = Age)) +
              geom_histogram(aes(y= ..density..), colour = "gray25", fill = "white") +
              geom_density(alpha=.2, fill ="red1") +
              theme(axis.line = element_line(size = 3, colour = "grey80"))
```

The Age Column has outliers, the previous histogram shows the distribution of the variable and shows that are some ages ahead of 100 years. Those middle age groups, 40 and 60 somethings, make up the majority of respondents. Even though, there is a notable number of respondents at ages of 60+.

```{r}
#Remove data points where Age>100
paste0("Number of Datapoints removed for Age>100: ", 
       sum(raw_ifood$Age > 100))
```

```{r}
raw_ifood <- raw_ifood %>% 
             filter(.,Age<100)

summary(raw_ifood$Age)
```

```{r}
# Making Dt_customer a date column
raw_ifood$Dt_Customer <- ymd(raw_ifood$Dt_Customer)
summary(raw_ifood$Dt_Customer)
```

## Analysis and Data Visualization of all features

For a better understanding of the data, I will plot each variable to visualize the distribution of the data and identify any outliers or imbalanced classes. Using mainly graphs like boxplots for quantitative variables and barplots (of value counts) for qualitative, categorical and binary (yes/no) variables.

### Grouping by People

```{r}
# Discrete variables
people_discrete <- raw_ifood %>% select(c('Education','Marital_Status',
                                          'Kidhome','Teenhome','Complain'))

# Continuous variables
people_continuous <- raw_ifood %>% select(c('Year_Birth','Income',
                                            'Dt_Customer','Recency'))
```

### Grouping by Product

```{r}
data_products <- raw_ifood %>% select(c('MntWines','MntFruits',
                                        'MntMeatProducts',
                                        'MntFishProducts',
                                        'MntSweetProducts',
                                        'MntGoldProds'))                                                                    
```

### Grouping by Place

```{r}
data_place <- raw_ifood %>% select(c('NumWebPurchases','NumCatalogPurchases',
                                     'NumStorePurchases','NumWebVisitsMonth'))
```

### Grouping by Promotion

```{r}
data_promotion <- raw_ifood %>% select(c('AcceptedCmp1','AcceptedCmp2','AcceptedCmp3',
                                         'AcceptedCmp4',
                                         'AcceptedCmp5',
                                         'Response',
                                         'NumDealsPurchases'))
```

```{r}
# Creating a key-value data set for each category
product_key_value     <- gather(data_products)
place_key_value       <- gather(data_place)
people_key_value_disc <- gather(people_discrete)
people_key_value_cont <- gather(people_continuous)
promotion_key_value   <- gather(data_promotion)
```

```{r}
# Plotting box plots for product variables
ggplot(product_key_value, aes(value))                                 +
geom_boxplot(alpha=.3, fill ="red1", colour = "gray25", notch = TRUE) +
facet_wrap(~key, scales = 'free_x', ncol = 3)                         +
labs(title = "Boxplot of Product Variables")                          +
theme(plot.title = element_text(hjust = 0.5))
```

-   It is important to notice that there seems to be nothing out of the expected in terms of the amount spent per product. Nevertheless, it is necessary to consider whether those customers who bought more than 1500 meat products over the past few years differ from the rest of the customers. In general, the outliers for these categories are all acceptable and valid values of purchases, and shall be kept as is.

```{r}
# Plotting bar-plots for promotion variables
ggplot(promotion_key_value, aes(value)) +
geom_histogram(stat = 'count',alpha=.3, fill ="red1", 
               colour = "gray25", position="identity") +
facet_wrap(~key, scales = 'free_x', ncol = 3) +
labs(title = "Bar Plots of Promotion Variables") +
theme(plot.title = element_text(hjust = 0.5))
```

-   It can be observed in Campaign Responses chart that campaigns one, three, four and five performed similarly, whereas campaign two performed poorly. The latest campaign (under variable 'Response') had the best performance.

```{r}
# Plotting histograms for place variables
ggplot(place_key_value, aes(value)) +
geom_histogram(stat = 'count', alpha=.3, fill ="red1", 
               colour = "gray25", position="identity", 
               binwidth = 1) +
facet_wrap(~key, scales = 'free_x', ncol = 2) +
labs(title = "Histograms of Place Variables") +
theme(plot.title = element_text(hjust = 0.5))
```

-   Generally speaking, each channel performs well in the early stages, but few customers continue to use these channels to continue shopping.

```{r}
# Ploting barplots for discrete people variables
ggplot(people_key_value_disc, aes(value))              +
geom_histogram(stat = 'count', alpha=.3, fill ="red1", 
               colour = "gray25", position="identity") +
facet_wrap(~key, scales = 'free_x', ncol = 2)          +
labs(title = "Bar Plots of Discrete People Variables") +
theme(plot.title = element_text(hjust = 0.15))
```

-   Complain: Very few customers have filed any complaints.
-   Education: The prevalent current highest level of education are Graduation, which is a little misleading as an education level, probably it refers to an "Undergraduate" education, Master degrees and Doctoral degrees.
-   Marital_Status: There are three categories 'Alone', 'YOLO' and 'Absurd' with very low number of customers in each.
-   Kidhome and Teenhome: The number of customers with two kid / teenager at home is very low, causing the classes to be very imbalanced.

```{r}
# Plotting histograms for continuous people variables
ggplot(people_key_value_cont, aes(value)) +
geom_histogram(bins = 50, alpha=.3, fill ="red1", 
               colour = "gray25", position="identity")    +
facet_wrap(~key, scales = 'free_x', ncol = 2) +
labs(title = "Histograms of Continuous People Variables") +
theme(plot.title = element_text(hjust = 0.5))
```

Before running a summary statistics we can actually visualize the range, central tendency and quartiles via a `geom_violin` call.

```{r}
df_num   <-select_if(raw_ifood, is.numeric) %>% select(-ID)
df_num_p <-df_num %>% gather(variable, values, 1:24)

df_num_p %>% ggplot() +
             geom_violin(aes(x = variable, y = values), 
                         alpha=.3, fill = "red1", 
                         colour = "gainsboro")  + 
             facet_wrap(~variable, ncol = 6, scales = "free") + 
             theme(strip.text.x = element_blank(),
             text = element_text(size = 7.5)) 
```

-   There are certain data points with high income.

```{r}
raw_ifood %>%
              ggplot(aes(x = Recency)) +
              geom_histogram(aes(y= ..density..), 
                             colour = "gray25", 
                             fill = "white") +
              geom_density(alpha=.2, fill ="red1") +
              theme(axis.line = element_line(size = 3, colour = "grey80"))
```

```{r}
raw_ifood %>%
  summarize(
    min = min(Income), 
    max = max(Income)
    )
```

-   Seems like I have customers earn a household income of more than \$600,000.

### The most successful marketing campaign

```{r}
# Counting ones
campaign_takeup <- raw_ifood %>% 
                   select('AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 
                          'AcceptedCmp4','AcceptedCmp5', 'Response') %>% 
                   colSums()
# Counting zeros
zero     <- function(x) sum(x == 0)
campaign <- raw_ifood %>% 
            select('AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 
                   'AcceptedCmp4','AcceptedCmp5', 'Response')
rechazo  <- numcolwise(zero)(campaign)
rechazo  <- as.data.frame(t(as.matrix(rechazo)))
colnames(rechazo) <- "no_aceptacion"

# Making a data frame with Acceptance and Rejected campaigns 
campaign_takeup <- data.frame(campana = c('AcceptedCmp1', 'AcceptedCmp2', 
                                          'AcceptedCmp3', 
                                          'AcceptedCmp4',
                                          'AcceptedCmp5', 
                                          'Response'),
                              aceptacion    = campaign_takeup[1:6],
                              no_aceptacion = rechazo)
```

```{r}
campaign_takeup_long <- melt(campaign_takeup)

ggplot(campaign_takeup_long, aes(x = campana, y = value, 
                                 fill = variable))+
geom_bar(stat = "identity", position= "dodge", 
         fill = c("#D20000"), alpha=.50,show.legend = NA) +
theme_bw() +
labs(x = "Campaign", y = "Acceptance", 
     title="Acceptance of Marketing Campaigns") + 
coord_flip() +
scale_y_continuous(labels = scales::comma)
```

-   From the bar plot, the most recent Marketing Campaign had the most success while Campaign2 had the least. In other words, based on the graph, we can conclude that the most recent campaign is the most successful one. It can be observed that campaigns 1, 3, 4 and 5 performed similarly. The latest campaign (under variable 'Response') had the best performance.

### Average customer profiling

```{r}
average_customer_num <- raw_ifood %>% 
                        select_if(names(.)=="Dt_Customer" | sapply(., is.numeric)) %>% 
                        select(-ID) %>% 
                        summarise_each(funs(mean)) %>%
                        t() %>% 
                        as.data.frame() %>% 
                        format(scientific = F, digits = 2) %>% 
                        setnames("V1", "average_customer")
                        
education      <- mlv(raw_ifood$Education, method="mfv")
status_marital <- mlv(raw_ifood$Marital_Status, method="mfv")
categ          <- data.frame(education,status_marital)

average_customer_categ <- categ %>%
                          t() %>% 
                          as.data.frame() %>% 
                          setnames("V1", "average_customer")

  
average_customer <- rbind(average_customer_num, average_customer_categ)
average_customer
```

Taking the modal category of all categorical variables to obtain the average customer profile for this iFood. According to the above analysis, the average customer profile can be divided into different categories:

Demographic:

-   Born between 1968 and 1969
-   Income: \$52.237
-   0.44 kids and 0.51 teens at home, for an average of 1 dependent at home
-   Graduated
-   Married

Expenditure in last two years:

-   Wine: 305.153
-   Fruits: 26.323
-   Meat: 166.962
-   Fish: 37.635
-   Sweet: 27.034
-   Gold: 43.911

Channels:

-   Deals Purchases: 2.325
-   Web Purchases: 4.087
-   Catalog Purchases: 2.671
-   Store Purchases: 5.805
-   Number of Web Visits in past month: 5.321

Loyalty:

-   Became a customer on 31-08-2012
-   Last made a purchase 49 days ago

Interactions:

-   Complains: 0.01
-   Accepted latest campaign: 0.15
-   Accepted Campaign 1: 0.064
-   Accepted Campaign 2: 0.013
-   Accepted Campaign 3: 0.073
-   Accepted Campaign 4: 0.075
-   Accepted Campaign 5: 0.073

### The best performing product

```{r}
products <- raw_ifood %>% 
            select('MntWines','MntFruits','MntMeatProducts',
                   'MntFishProducts','MntSweetProducts',
                   'MntGoldProds') %>% 
            colSums()
products <- data.frame(producto = c('MntWines','MntFruits',
                                    'MntMeatProducts','MntFishProducts',
                                    'MntSweetProducts','MntGoldProds'),
                       suma_total = products[1:6])
```

```{r}
ggplot(data = products) +
geom_bar(mapping = aes(x = reorder(producto, suma_total), y = suma_total), 
         stat = "identity", 
         fill = c("firebrick4","darkred","#C00000","#FF3334","#FF6F77","#FFBBC1"), 
         alpha=.60) +
theme_bw() +
labs(x = "Product Category", y = "Number Sold", title="Product Performance in last few years") + 
coord_flip() +
scale_y_continuous(labels = scales::comma)
```

-   The best performing product is Wine followed by Meat Products. Based on the chart, we can see that wine performed the best, with the highest number of items sold, followed by meat products. On the other hand, Gold, Fish, Sweet and Fruits products are less popular, with similar number of items sold.

### The best performing channel

```{r}
channels <- raw_ifood %>% 
            select('NumDealsPurchases', 'NumCatalogPurchases', 
                   'NumWebPurchases', 
                   'NumStorePurchases') %>% 
            colSums()
channels <- data.frame(canal = c('NumDealsPurchases', 'NumCatalogPurchases', 
                                 'NumWebPurchases', 
                                 'NumStorePurchases'),
                       suma_total = channels[1:4])
```

```{r}
ggplot(data = channels) +
geom_bar(mapping = aes(x = reorder(canal, suma_total), y = suma_total), 
         stat = "identity", 
         fill = c("firebrick4","darkred","#C00000","#FF3334"), 
         alpha=.60) +
theme_bw() +
labs(x = "Chanel Category",y = "Number of purchases using that channel",
     title = "Channel Performance in last few years") + 
coord_flip() +
scale_y_continuous(labels = scales::comma)
```

-   Based on the chart, we can see that most customers preferred purchasing in physical stores, as it has the most number of items sold. This is followed by online website, catalog, and deals. Deals is the most under-performing channel.

## Data exploration of dependent variables

-   I will use correlation matrix to find the correlations among features. The cor() method can be applied on dataframe and the results can also be visualized using a heatmap.

### Features Correlation Analysis

```{r, fig.width=7,fig.height=7}
data_numeric <- raw_ifood %>% select_if(., is.numeric) %>% select(-c("AcceptedCmp1","AcceptedCmp2",
                                                                     "AcceptedCmp3","AcceptedCmp4",
                                                                     "AcceptedCmp5","Recency",
                                                                     "Complain","ID","Z_CostContact",
                                                                     "Z_Revenue","Year_Birth"))
crr <- cor(data_numeric, use="complete.obs")

#Visualizing correlation in heatmap
colores <- colorRampPalette(c("dodgerblue", "ghostwhite", "firebrick2"))(20)
heatmap(crr, col = colores, symm=TRUE)   
```

```{r, fig.width=9,fig.height=9}
corrplot(corr = crr, 
         method="number", 
         col = colores, 
         type="upper", 
         tl.col="black", 
         order="hclust")
```

-   Highly positively correlated variables are in Red and Highly negatively correlated variables are in Blue.
-   We could see that income are positively correlated to Number of purchases and the amount of purchases.
-   The different kind of purchases such as Meat purchases/ Sweet purchases/ Fish purchases/ Fruit purchases tend to be positively correlated to one another.
-   There are negative correlations between having kids/ dependents at home and the amount or number of purchases.

### Correlation Analysis - correlationfunnel

```{r}
customer_ifoof_binarized <- raw_ifood %>%
                            select(-ID,-Year_Birth,-Z_CostContact,-Z_Revenue, -Dt_Customer) %>%
                            binarize(n_bins = 5, thresh_infreq = 0.01, name_infreq = "OTHER", one_hot = TRUE)

customer_response_corr  <- customer_ifoof_binarized %>%
                           correlate(Response__1)

customer_response_corr %>%
  plot_correlation_funnel()
```

We can see that the correlation funnel graph produced uncovers insights by elevating high-correlation features and lowering low-correlation features:

-   Income is a proxy for several other features, such as the amount spend, positively driven by meat and wine and it has a negative correlation with the number of kids home and the visits on the websites.
-   The amount spend on wine is, besides being related to high income, to the amount spend on meat and it is purchased or in Catalog or Stores.
-   The number of kids is negative related to income. Higher Income is also related to accept Campaigns.

# Section 02: Customer segmentation

## Customer Profile Analysis

```{r}
raw_ifood %>% 
  ggplot(aes(x = Age, y = Income, color = Teenhome, size = Recency)) +
  geom_point(alpha = 0.25) +
   labs(title = "Customers response according to their age and income") +
  facet_wrap(~Response) +
  scale_y_continuous(labels = scales::comma)
```

```{r}
plot_1 <- raw_ifood %>% 
          select(Income, Age) %>%
          group_by(Age) %>% 
          ggplot(aes(x = Age, y = Income))   +
          geom_col(alpha=.15, colour = c("#D90A27"))  + 
          scale_y_continuous(labels = scales::dollar) +
          ggtitle("Mean Income by Age") +
          theme(legend.title = element_blank())

plot_2 <- raw_ifood %>% 
          select(Income, Education) %>%
          group_by(Education) %>% 
          ggplot(aes(x = Education, y = Income))   +
          geom_col(alpha=.05, colour = c("#E74C4A"), width = 0.77) + 
          scale_y_continuous(labels = scales::dollar) +
          ggtitle("Mean Income by Education") +
          theme(legend.title = element_blank())

plot_3 <-raw_ifood %>% 
         select(Income, Marital_Status) %>%
         group_by(Marital_Status) %>% 
         ggplot(aes(x = Marital_Status, y=Income))   +
         geom_col(alpha=.05, colour = c("#E73927"), width = 0.45)  + 
         scale_y_continuous(labels = scales::dollar) +
         ggtitle("Mean Income by Marital Status") +
         theme(legend.title = element_blank())
```

```{r}
gs <- lapply(1:9, function(ii) 
grobTree(rectGrob(gp=gpar(fill=ii, alpha=0.5)), textGrob(ii)))
```

```{r,fig.width=12,fig.height=9}
lay <- rbind(c(1,1,1,2,2),
             c(1,1,1,3,3))
grid.arrange(plot_1, plot_2, plot_3, layout_matrix = lay)
```

```{r}
graph_1 <- ggplot(raw_ifood, aes(x = Marital_Status, fill= Marital_Status)) + 
           geom_bar(alpha=.60)                                              +
           scale_fill_manual(values = c("firebrick4","darkred","#C00000",
                                        "#FF3334","#FF6F77","#FFBBC1","#FFDEE3",
                                        "#FF8896"))

graph_2 <- ggplot(raw_ifood, aes(x = Education, fill= Education)) + 
           geom_bar(alpha=.60)                                    +
           scale_fill_manual(values = c("firebrick4","darkred","#C00000","#FF3334",
                                        "#FF6F77","#FFBBC1","#FFDEE3","#FF8896"))
           
graph_3 <- ggplot(raw_ifood, aes(x = Education, fill= Marital_Status)) +
           geom_bar(position = position_fill(), alpha=.60) +
           scale_fill_manual(values = c("firebrick4","darkred","#C00000","#FF3334",
                                        "#FF6F77","#FFBBC1","#FFDEE3","#FF8896"))
```

```{r, fig.width=8, fig.height=10}
grid.arrange(graph_1, graph_2, graph_3, nrow = 3,
             bottom = textGrob("Customer Profile Information",
             gp = gpar(fontface = 3, fontsize = 9),
             hjust = 1,
             x = 1))
```

## Statistical Clustering - K-Means

The segmentation will be performed using K-Means clustering, which is a simple and elegant way of sub-setting the customers into non-overlapping segments.

-   I specify the number of clusters that I need to create.
-   The algorithm selects k objects at random from the data set. This object is the initial cluster or mean.
-   The closest centroid obtains the assignment of a new observation. I base this assignment on the Euclidean Distance between object and the centroid.

```{r}
ifood_df_clustering = raw_ifood %>% 
                      select(-ID,-Education,-Marital_Status,-Dt_Customer,
                             -Year_Birth,-Z_CostContact,-Z_Revenue,-Response)
```

-   Importance of Scaling the Data before Performing K-Means: In the iFood data, the variables are measured in different units, where a unit increase or decrease in one day for the Recency (days inactive) is completely different than a unit increase or decrease in dollars for the Income feature. Therefore the importance of scaling the data, to represent the true distance among variables. The data has been scaled using the function scale() in the k-means algorithm.

### Elbow method

```{r}
# function to calculate total intra-cluster sum of square (euclidean distance)
set.seed(20)
ics <- function(k){
  kmeans(scale(ifood_df_clustering), k, iter.max = 100, 
         nstart = 100, algorithm = "Lloyd")$tot.withinss
}

k_values   <- 1:12
ics_values <- map_dbl(k_values, ics)
```

```{r}
plot(k_values, ics_values, 
     type = "b", pch = 19, frame = FALSE, col="indianred3", 
     cex=1, lwd = 2, lty = 2,
     xlab = "Number of clusters K",
     ylab = "Total intra-clusters sum of squares",
     main = 'Total within-group sum of squares vs. cluster count')
```

-   Fitting k-means to the data set with K = 2 or 3. From the above graph, we conclude that 4 is the appropriate number of clusters since it seems to be appearing at the bend in the elbow plot.

### Silhouette method

```{r}
# average Silhouette method
k2 <-  kmeans(scale(ifood_df_clustering), 2,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k3 <-  kmeans(scale(ifood_df_clustering), 3,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k4 <-  kmeans(scale(ifood_df_clustering), 4,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k5 <-  kmeans(scale(ifood_df_clustering), 5,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k6 <-  kmeans(scale(ifood_df_clustering), 6,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k7 <-  kmeans(scale(ifood_df_clustering), 7,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k8 <-  kmeans(scale(ifood_df_clustering), 8,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k9 <-  kmeans(scale(ifood_df_clustering), 9,  iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
k10 <- kmeans(scale(ifood_df_clustering), 10, iter.max = 100, 
              nstart = 50, algorithm = "Lloyd")
```

Now, I make use of the `fviz_nbclust()` function to determine and visualize the optimal number of clusters

```{r}
fviz_nbclust(scale(ifood_df_clustering), kmeans, method = "silhouette")
```

### Gap statistic method

```{r}
set.seed(125)
stat_gap <- clusGap(ifood_df_clustering, FUN = kmeans, nstart = 25,  
            K.max = 8, B = 60)
fviz_gap_stat(stat_gap)
```

Now, considering previous analysis, lets take K = 2 as optimal cluster

```{r}
k2 <- kmeans(scale(ifood_df_clustering), 2,  iter.max = 100, 
             nstart = 50, algorithm = "Lloyd")
k2
```

```{r}
# principal component analysis
pcclust = prcomp(ifood_df_clustering, scale = TRUE) 
summary(pcclust)
pcclust$rotation[,1:2]
```

```{r}
# Cluster centres
k2$centers
```

## Analyze customer segments

```{r}
# Analyze clusters
colMeans(ifood_df_clustering[k2$cluster == 1, 1:22])
colMeans(ifood_df_clustering[k2$cluster == 2, 1:22])
```

```{r,fig.width=8, fig.height=6}
# Plot clusters
plot(ifood_df_clustering[,5:10], col = k2$cluster, 
     main = "Average scores for customers coloured by k-means cluster")
```

```{r,fig.width=8, fig.height=6}
# Plot clusters
plot(ifood_df_clustering[,11:14], col = k2$cluster, 
     main = "Average scores for customers coloured by k-means cluster")
```

```{r}
set.seed(15)
ggplot(raw_ifood, aes(x = Age, y = Income, size = Teenhome)) + 
  geom_point(alpha = 0.25, stat = "identity", 
             aes(color = as.factor(k2$cluster))) +
  scale_color_discrete(name=" ",
              breaks=c("1", "2"),
              labels=c("Cluster 1", "Cluster 2")) +
  ggtitle("Segments of Customers", 
          subtitle = "Using K-means Clustering")  +
  scale_y_continuous(labels = scales::comma)
```

```{r}
kCols = function(vec){cols=rainbow (length (unique (vec)))
return (cols[as.numeric(as.factor(vec))])}
digCluster <- k2$cluster
dignm      <-as.character(digCluster) # K-means clusters
plot(pcclust$x[,1:2], col = kCols(digCluster), pch = 19, xlab ="K-means", ylab = "classes")
legend("bottomleft", unique(dignm), fill = unique(kCols(digCluster)))
```

+---------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------+
| Cluster 1 - **Low Value Customers**                                                                     | Cluster 2 - **High Value Customers**                                                                    |
+=========================================================================================================+=========================================================================================================+
| -   Low or average level of income                                                                      | -   High level of income                                                                                |
|                                                                                                         |                                                                                                         |
| -   The majority has one kid or teenager at home                                                        | -   Meat and wine are preferred                                                                         |
|                                                                                                         |                                                                                                         |
| -   Represents the most part of basic level of education                                                | -   The majority has no children                                                                        |
|                                                                                                         |                                                                                                         |
| -   Low number of purchases through store purchase. They prefer web purchases or make catalog purchases | -   Low web visit and high store purchase                                                               |
|                                                                                                         |                                                                                                         |
| -   Negative effect of having kids and teens on advertising campaign acceptance                         | -   Number of store purchases decreases when there are kids                                             |
|                                                                                                         |                                                                                                         |
|                                                                                                         | -   Selection of wines and fruits, as well as the attractive deals attract customers with higher income |
+---------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------+

: Customers segmentation

# Section 03: Predictive model (Classification)

```{r}
# Selecting the data 
ifood_ml <- raw_ifood %>% 
            select(-ID,-Year_Birth,-Z_CostContact,-Z_Revenue) %>% 
            mutate(Income = log10(Income)) %>% 
            mutate_if(is.character, factor) %>% 
            mutate(Response = as.factor(Response)) %>% 
            mutate(AcceptedCmp1 = as.factor(AcceptedCmp1)) %>%
            mutate(AcceptedCmp2 = as.factor(AcceptedCmp2)) %>%
            mutate(AcceptedCmp3 = as.factor(AcceptedCmp3)) %>%
            mutate(AcceptedCmp4 = as.factor(AcceptedCmp4)) %>%
            mutate(AcceptedCmp5 = as.factor(AcceptedCmp5)) %>% 
            mutate(Complain     = as.factor(Complain))
```

## Build a model

```{r}
set.seed(123)
ifood_ml_split <- initial_split(data =  ifood_ml, strata = Response)
ifood_ml_train <- training(ifood_ml_split)
ifood_ml_test  <- testing(ifood_ml_split) 
```

```{r}
# Computer performance
set.seed(234)
ifood_ml_boot <- bootstraps(ifood_ml_train)
```

```{r}
# Setting a Random Forest
rf_spec <- rand_forest() %>% 
           set_mode("classification") %>% 
           set_engine("ranger", importance = "permutation") # "spark","randomForest"
```

```{r}
ifood_ml_wf <- workflow() %>% 
               add_formula(Response ~ .)
ifood_ml_wf
```

```{r}
# Training with the bootstraps
rf_rs <- ifood_ml_wf %>% 
         add_model(rf_spec) %>% 
         fit_resamples(resamples = ifood_ml_boot,
                       control = control_resamples(save_pred = TRUE, verbose = TRUE))
rf_rs
```

## Evaluate modeling

```{r}
collect_metrics(rf_rs)
```

```{r}
rf_rs %>% 
  conf_mat_resampled()
```

```{r}
rf_rs %>% 
  collect_predictions() %>% 
  group_by(id) %>% 
  roc_curve(Response, .pred_0) %>% 
  ggplot(aes(x = 1 - specificity, y = sensitivity, color = id)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_path(show.legend = FALSE, alpha = 0.6, size = 1.2) +
  coord_equal() 
```

```{r}
# Back to the testing data
ifood_ml_final <- ifood_ml_wf %>% 
                  add_model(rf_spec) %>% 
                  last_fit(ifood_ml_split)
ifood_ml_final
```

```{r}
collect_metrics(ifood_ml_final)
```

```{r}
ifood_ml_final %>% 
  collect_predictions() %>% 
  conf_mat(Response, .pred_class)
```

```{r}
ifood_ml_final$.workflow[[1]]
```

```{r}
ifood_ml_final %>% 
  pluck(".workflow", 1) %>%   
  pull_workflow_fit()   %>% 
  vip(aesthetics = list(alpha = 0.35, fill = "firebrick2"), 
      num_features = 25)
```

-   Among the most important variables for the proposed machine learning model, the number of days since the last purchase ('Recency') is very important.
-   Because purchasing in store, on the web, or via the catalog ('NumStorePurchases', 'NumWebPurchases', 'NumCatalogPurchases') is positively correlated with 'Income'. Eventually, these variables become significant.
-   The history of past campaigns are also crucial factors to this prediction.
-   Nevertheless, variables such as 'Complain','Age' of the customer or 'Marital_Status' are not so crucial for the model.

# Chief Marketing Officer Recommendations

Based on the findings in the sections above, I provide the following data-driven recommendations:

1.  Channel Recommendations

    -   Number of every kind of purchase is influenced by the income level of the customers, when there is increase in the number of web/catalog purchases, there is a reduction in store purchases.

    -   The under-performing channels are deals and catalog purchases (the average customer made the fewest purchases via these channels).

    -   The best performing channels are web and store purchases (the average customer made the most purchases via these channels). Focus advertising campaigns on the more successful channels, to reach more customers.

2.  Product Recommendations

    -   Customers who spend more on Wines and Meat products tend to spend less on Fish products.

    -   Wines and Meat products are the top two best performing products in terms of sales. Deals and promotions should be carried out to increase the sales of other products. Focus advertising campaigns on boosting sales of the less popular items.

3.  Campaign Recommendations

    -   Overall Campaigns have not done well for this company.

    -   Create two streams of targeted advertising campaigns, one aimed at high-income individuals without kids/teens and another aimed at lower-income individuals with kids/teens.

4.  Customer Loyalty Recommendations

    -   CMO should consider some loyalty program or rewards for members to increase stickiness & purchase frequency. This is because engagement within members is rather low, as many have been members for over a year, but median recency (days since last purchase) is approximately 50 days. Considering the store has a large variety of fresh products (Fruits, Fish & Meat), they would prefer weekly / biweekly visits of customers.

    -   Another thing to take into account, is inventing a reward system unique to the store channel will enhance consumer engagement and is expected to increase the number of instore purchases.

    -   The marketing department should target customers with Teens in order to increase the number of store purchases. On the other hand should not target customers with with Kids because this will decrease the number of store purchases.

5.  iFood Data Science Team

    -   To strengthen the machine learning model it would be useful to add data such as the country where the customer is located, rating in terms of perception of the company and satisfaction surveys.

    -   Since the description, data analysis and model building was done based on customer consumption habits, the model results may vary somewhat in the case where these habits vary drastically.

    -   In order to improve the previous analysis, it is important to have multidisciplinary iFood teams to understand the problem holistically. Therefore the intervention of the distribution and logistics, advertising, communication and image, public relations teams is timely.

    -   The methodology and algorithm used previously works well to be able to perform different experiments varying the amount of data. However, it is important to consider a scalable model using technologies such as Hadoop ecosystem with the Mahout machine-learning framework or Spark ecosystem with the MLlib machine-learning library.
